{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49441344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "pwd=Path.cwd()\n",
    "ROOT=pwd.parent\n",
    "import sys\n",
    "sys.path.append(str(ROOT))\n",
    "from utils import *\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b5f3cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn import init\n",
    "\n",
    "def build_dataset(batch_size=32, n_samples=1000):\n",
    "    \"\"\"\n",
    "    构建训练数据集：\n",
    "    - x: (n_samples, 2, 28, 28) 模拟双通道28×28数据\n",
    "    - y: (n_samples,) 类别索引（0-9）\n",
    "    \"\"\"\n",
    "    # 生成输入数据（添加轻微噪声，模拟真实数据）\n",
    "    x = torch.randn(n_samples, 2, 28, 28) * 0.5 + 0.5  # 均值0.5，方差0.5，更贴近真实数据分布\n",
    "    \n",
    "    # 生成标签（与输入弱关联，避免完全随机）\n",
    "    net_temp = A_simple_net()  # 用临时网络生成伪得分\n",
    "    with torch.no_grad():  # 不计算梯度，仅用于生成标签\n",
    "        x_flat = net_temp.flatten(x)\n",
    "        pseudo_score = net_temp.linear.simulate(x_flat)\n",
    "    y = torch.argmax(pseudo_score, dim=1)  # 基于伪得分生成类别索引\n",
    "    \n",
    "    # 构建Dataset和DataLoader\n",
    "    dataset = TensorDataset(x, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    return dataloader\n",
    "\n",
    "def train(epochs: int, dataloader, model, optimizer, loss_fn, use_simulate_verify=False):\n",
    "    \"\"\"\n",
    "    训练函数：\n",
    "    - use_simulate_verify: 是否用simulate函数验证forward结果（仅用于调试）\n",
    "    \"\"\"\n",
    "    model.train()  # 设置训练模式\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        batch_count = 0\n",
    "        \n",
    "        for x_batch, y_batch in dataloader:\n",
    "            # ---------------------- 数据预处理 ----------------------\n",
    "            x_batch = x_batch.float()  # 确保输入为float类型\n",
    "            # 归一化到[0,1]（若原始数据范围过大，避免梯度爆炸）\n",
    "            if x_batch.max() > 1:\n",
    "                x_batch = x_batch / x_batch.max()\n",
    "            \n",
    "            # 确保标签为long类型（交叉熵损失要求）\n",
    "            y_batch = y_batch.long()\n",
    "            \n",
    "            # ---------------------- 前向传播 ----------------------\n",
    "            out = model(x_batch)  # 训练用forward\n",
    "            loss = loss_fn(out, y_batch)  # 官方损失计算\n",
    "            \n",
    "            # （可选）用simulate验证结果一致性（调试用）\n",
    "            if use_simulate_verify and epoch == 0 and batch_count == 0:\n",
    "                out_sim = model.simulate(x_batch)\n",
    "                loss_sim = loss_fn.simulate(out, y_batch)\n",
    "                print(f\"=== 训练首轮验证（forward vs simulate）===\")\n",
    "                print(f\"输出误差（L2范数）: {torch.norm(out - out_sim).item():.6f}\")\n",
    "                print(f\"损失误差: {abs(loss.item() - loss_sim.item()):.6f}\")\n",
    "            \n",
    "            # ---------------------- 反向传播+参数更新 ----------------------\n",
    "            optimizer.zero_grad()  # 梯度清零\n",
    "            loss.backward()  # 反向传播\n",
    "            optimizer.step()  # 参数更新\n",
    "            \n",
    "            # ---------------------- 损失统计 ----------------------\n",
    "            total_loss += loss.item()\n",
    "            batch_count += 1\n",
    "        \n",
    "        # ---------------------- 每轮日志 ----------------------\n",
    "        avg_loss = total_loss / batch_count\n",
    "        # 保存最优模型（基于训练损失）\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            torch.save(model.state_dict(), \"best_softmax_model.pth\")  # 保存模型参数\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:2d} | Avg Loss: {avg_loss:.6f} | Best Loss: {best_loss:.6f}\")\n",
    "    \n",
    "    print(f\"\\n训练结束！最优模型已保存为 'best_softmax_model.pth'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a18d0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集构建完成：共2000个样本，批次大小32，共62个批次\n",
      "=== 训练首轮验证（forward vs simulate）===\n",
      "输出误差（L2范数）: 0.000000\n",
      "损失误差: 0.000000\n",
      "Epoch  1 | Avg Loss: 28.275754 | Best Loss: 28.275754\n",
      "Epoch  2 | Avg Loss: 6.949462 | Best Loss: 6.949462\n",
      "Epoch  3 | Avg Loss: 1.539084 | Best Loss: 1.539084\n",
      "Epoch  4 | Avg Loss: 0.640247 | Best Loss: 0.640247\n",
      "Epoch  5 | Avg Loss: 0.458476 | Best Loss: 0.458476\n",
      "Epoch  6 | Avg Loss: 0.118787 | Best Loss: 0.118787\n",
      "Epoch  7 | Avg Loss: 0.042850 | Best Loss: 0.042850\n",
      "Epoch  8 | Avg Loss: 0.012965 | Best Loss: 0.012965\n",
      "Epoch  9 | Avg Loss: 0.003017 | Best Loss: 0.003017\n",
      "Epoch 10 | Avg Loss: 0.001397 | Best Loss: 0.001397\n",
      "Epoch 11 | Avg Loss: 0.001406 | Best Loss: 0.001397\n",
      "Epoch 12 | Avg Loss: 0.001340 | Best Loss: 0.001340\n",
      "Epoch 13 | Avg Loss: 0.001444 | Best Loss: 0.001340\n",
      "Epoch 14 | Avg Loss: 0.001520 | Best Loss: 0.001340\n",
      "Epoch 15 | Avg Loss: 0.001721 | Best Loss: 0.001340\n",
      "Epoch 16 | Avg Loss: 0.001845 | Best Loss: 0.001340\n",
      "Epoch 17 | Avg Loss: 0.002057 | Best Loss: 0.001340\n",
      "Epoch 18 | Avg Loss: 0.002386 | Best Loss: 0.001340\n",
      "Epoch 19 | Avg Loss: 0.002421 | Best Loss: 0.001340\n",
      "Epoch 20 | Avg Loss: 0.002712 | Best Loss: 0.001340\n",
      "Epoch 21 | Avg Loss: 0.003022 | Best Loss: 0.001340\n",
      "Epoch 22 | Avg Loss: 0.003271 | Best Loss: 0.001340\n",
      "Epoch 23 | Avg Loss: 0.003596 | Best Loss: 0.001340\n",
      "Epoch 24 | Avg Loss: 0.004132 | Best Loss: 0.001340\n",
      "Epoch 25 | Avg Loss: 0.004561 | Best Loss: 0.001340\n",
      "Epoch 26 | Avg Loss: 0.004950 | Best Loss: 0.001340\n",
      "Epoch 27 | Avg Loss: 0.005485 | Best Loss: 0.001340\n",
      "Epoch 28 | Avg Loss: 0.006083 | Best Loss: 0.001340\n",
      "Epoch 29 | Avg Loss: 0.006341 | Best Loss: 0.001340\n",
      "Epoch 30 | Avg Loss: 0.007027 | Best Loss: 0.001340\n",
      "Epoch 31 | Avg Loss: 0.007451 | Best Loss: 0.001340\n",
      "Epoch 32 | Avg Loss: 0.008389 | Best Loss: 0.001340\n",
      "Epoch 33 | Avg Loss: 0.008943 | Best Loss: 0.001340\n",
      "Epoch 34 | Avg Loss: 0.009929 | Best Loss: 0.001340\n",
      "Epoch 35 | Avg Loss: 0.010968 | Best Loss: 0.001340\n",
      "Epoch 36 | Avg Loss: 0.011053 | Best Loss: 0.001340\n",
      "Epoch 37 | Avg Loss: 0.012112 | Best Loss: 0.001340\n",
      "Epoch 38 | Avg Loss: 0.013438 | Best Loss: 0.001340\n",
      "Epoch 39 | Avg Loss: 0.014917 | Best Loss: 0.001340\n",
      "Epoch 40 | Avg Loss: 0.015604 | Best Loss: 0.001340\n",
      "Epoch 41 | Avg Loss: 0.016019 | Best Loss: 0.001340\n",
      "Epoch 42 | Avg Loss: 0.016197 | Best Loss: 0.001340\n",
      "Epoch 43 | Avg Loss: 0.017407 | Best Loss: 0.001340\n",
      "Epoch 44 | Avg Loss: 0.017705 | Best Loss: 0.001340\n",
      "Epoch 45 | Avg Loss: 0.019590 | Best Loss: 0.001340\n",
      "Epoch 46 | Avg Loss: 0.019636 | Best Loss: 0.001340\n",
      "Epoch 47 | Avg Loss: 0.018098 | Best Loss: 0.001340\n",
      "Epoch 48 | Avg Loss: 0.020013 | Best Loss: 0.001340\n",
      "Epoch 49 | Avg Loss: 0.019229 | Best Loss: 0.001340\n",
      "Epoch 50 | Avg Loss: 0.020427 | Best Loss: 0.001340\n",
      "\n",
      "训练结束！最优模型已保存为 'best_softmax_model.pth'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # 1. 配置训练参数\n",
    "    EPOCHS = 50  # 训练轮数\n",
    "    BATCH_SIZE = 32  # 批次大小\n",
    "    LEARNING_RATE = 0.5  # 学习率（适配SGD+动量）\n",
    "    N_SAMPLES = 2000  # 模拟训练样本数\n",
    "    \n",
    "    # 2. 构建数据加载器\n",
    "    train_dataloader = build_dataset(batch_size=BATCH_SIZE, n_samples=N_SAMPLES)\n",
    "    print(f\"数据集构建完成：共{N_SAMPLES}个样本，批次大小{BATCH_SIZE}，共{len(train_dataloader)}个批次\")\n",
    "    \n",
    "    # 3. 初始化模型、损失函数、优化器\n",
    "    model = A_simple_net()  # 推荐使用（无内置Softmax，适配CrossEntropyLoss）\n",
    "    # model = Softmax_Regression()  # 可选：带Softmax输出（需改用NLLLoss，注释下方loss_fn，启用第148行）\n",
    "    \n",
    "    loss_fn = Loss_cross_entropy()  # 交叉熵损失（内置Softmax，适配A_simple_net）\n",
    "    # loss_fn = nn.NLLLoss()  # 若用Softmax_Regression，需用NLLLoss（输入为概率的log）\n",
    "    \n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=LEARNING_RATE,\n",
    "        momentum=0.9,  # 动量加速收敛\n",
    "        weight_decay=1e-4  # L2正则化，防止过拟合\n",
    "    )\n",
    "    \n",
    "    # 4. 启动训练（use_simulate_verify=True 可验证simulate函数）\n",
    "    train(\n",
    "        epochs=EPOCHS,\n",
    "        dataloader=train_dataloader,\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        loss_fn=loss_fn,\n",
    "        use_simulate_verify=True  # 训练首轮验证forward与simulate一致性\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
